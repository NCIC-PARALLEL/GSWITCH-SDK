\section{Introduction}
\todo[inline, color=red!40]{xxxxxxx}


Precision medicine has becoming a promising and efficient approach to clinical diagnoses, allowing patients to be treated with personalized medicine based on a genetic understanding of their disease. For instance, those with leukemia, breast, lung, colon, and rectal cancers are usually tested for certain genetic changes if they develop melanoma..~\cite{shendure2008next,chang2016smem,cong2017aim}. It is predicted that by 2025, 1 billion people will have their own genomes, generating up to 40 exabytes a year of genomic data. This data in turn has led to a plethora of genetic analysis tools~\cite{li2013aligning,li2009sequence,McKenna01092010,picard,SMALT}. Table I depicts three typical genomic analysis flows~\cite{hiseq}. Whole-Genome Sequencing (WGS) provides a base-by-base view of the mutations while Whole-Exome Sequencing (WES) only identifies the coding mutations in cancer, which are less than 2\% of the genome and most likely to contain mutations. Panel targeted special mutations in a given sample.

To keep up with this data deluge, previous studies have focused on providing large-scale or in-memory software framework~\cite{HugeSeq,Massie:EECS-2013-207}. However, using traditional large-scale computing systems will lead to an unaffordable cost of personalized medicine which is advocated to benefit the mass. Furthermore, traditional computer architecture composes of heavy-weight cores and large on-chip caches, which needs to move the massive amount of genomic data from memory to CPU. Another approach is using specialized on-chip accelerators for a particular algorithm or operations case-by-case~\cite{ahmed2015heterogeneous, houtgast2016gpu, liu2012evaluation,chang2016smem, fernandez2011string}. However, these approaches face two challenges. The first challenge is \textit{how to find the next acceleration targets?} As shown in Table I, different scenarios and use cases often necessitate different application combinations. There is a surprising lack of research on the interactions of comprehensive genomic applications with the underlying microarchitecutre. The second challenge is that \textit{system performance is limited by the main memory capacity and bandwidth per server.} Due to the pin count limitation per chip, For instance, Kocberber et al.~\cite{Kocberber:2013bb} observed that using more than four index traversal units. Wang et al.~\cite{yuanrong} observed that using more than 48 PEs do not provide additional speedup due to off-chip bandwidth limitations. Genomic workloads are known to put more pressure on memory bandwidth due to 1) large amounts of random memory access across large input data, which reduces the efficiency of cache system; 2) small computations per loci. These two reasons make it difficult to dig the inherent parallelism of genomic applications with memory hierarchy on conventional architecture.

To provide a higher effective memory bandwidth, processing-in-memory (PIM) and near data processing (NDP) architectures presents new opportunities by integrating compute-logic near memory. 
The recent advancement in integrated circuit (IC) process technology makes these architectures feasible, specifically that of 3D stacking process technology~\cite{zhu2013accelerating,Neurocube,GraphPIM,3Dstacking}.
Hybrid memory cube (HMC)~\cite{HMCSpec}, high bandwidth memory (HBM)~\cite{HBMSpec} are promising memory designs that leverage the benefits of 3D stacking. Such stacked present a viable alternative for addressing this bottleneck leveraging on many processing cores embedded into DRAM. The key objective of adopting PIM is not solely to provide high memory bandwidth, but also to increase scalability for well designed parallel algorithms. In comparison with the integration of compute-logic on the base die, PIM allows the CPU to dispatch parts of the application for execution on compute units that are close to DRAM. Offloading computation using PIM has two major benefits. First, it eliminates a significant portion of the data movement between main memory and conventional processors. Second, it can take advantage of the high-bandwidth and low-latency access to the data inside 3D-stacked DRAM.

The goal of this paper is understanding and mitigating data movement bottlenecks for genomic workloads. We show that the processing-in-memory (PIM) can be a key enabler to realize memory-capacity-proportional performance in large-scale genomic processing under the current pin count limitation. By putting computation logic units on the logic die of 3D-stacked memory, latency and energy overheads of moving data between computation units and main memory can be reduced as well. To investigate the potential benefits of PIM, we first extract commonly used kernels from different genome analysis pipelines, as they account for a significant of the flow execution time. An entire genomic analysis flow can be expressed in a combination of several kernels. Using kernels to express applications is highly intuitive, allowing architecture designers to focus on the behaviors of kernels. We extracted commonly used kernels such as hash-based, fm-index, graph traversal, smith-waterman. Second, we delve further into each kernel to understand what underlying functions and characteristics contribute the most to data movement, which leads to a second key observation: genomic kernels are often with simple functions and primitives (which we refer to small computation) that are responsible for a significant fraction of the total data movement. These operations are comprised of simple operations such as memcopy, memset, shift, and basic arithmetic and bitwise operations. Finally, we proposed three mechanisms to be able to take advantage of today's 3D integration technology in a cost-effective manner. 

In summary, this paper makes the following contributions.

\begin{itemize}
    \item We study a wide range of genomic workloads and extracted commonly used kernels.
    
    \item We analyze the data movement of these kernels from the computer architecture perspective and show that memoryc subsystem is the main bottleneck. We demonstrate that the key performance benefit of PIM for genomic computing comes from leveraging inherent parallelism with customized accelerator.
    
    \item We proposed three mechanisms that can effectively utilize PIM using 3D-stacked memory technologies. Our new design is called GeneP. These mechanisms (1) enable efficient allocation of genome data across 3D-stacked memory cube, (2) effectively hide of long remote access latencies via the use of non-blocking message passing, and (3) maximize the utilization of available memory bandwidth and PE resources.
    
    \item We provide case studies of how FM-index kernel can be mapped to our architecture and how it can benefit from it. Our evaluations shown that GeneP achieves around 20$\times$ speedup compared to the best available ASIC solution, and 1820$\times$ speedup with the software solution with 7032$\times$ speedup (performance/watt) energy reduction over conventional systems.
\end{itemize}